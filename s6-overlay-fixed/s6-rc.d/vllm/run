#!/command/with-contenv bash
set -e

echo "=== Starting vLLM service ==="

sleep 3

if command -v nvidia-smi &> /dev/null; then
    echo "GPU detected:"
    nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv || true
else
    echo "WARNING: No NVIDIA GPU detected"
fi

echo "vLLM configuration:"
echo "  Model: $VLLM_MODEL"
echo "  Host: $VLLM_HOST"
echo "  Port: $VLLM_PORT" 
echo "  GPU Memory: $VLLM_GPU_MEMORY_UTILIZATION"

if [ -z "$VLLM_MODEL" ]; then
    echo "ERROR: VLLM_MODEL not configured"
    exit 1
fi

echo "Starting vLLM..."

exec vllm serve "$VLLM_MODEL" \
    --host "$VLLM_HOST" \
    --port "$VLLM_PORT" \
    --gpu-memory-utilization "$VLLM_GPU_MEMORY_UTILIZATION"
