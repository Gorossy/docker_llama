#!/command/with-contenv bash
set -e

echo "Iniciando servicio vLLM..."

# Esperar un momento para que SSH esté completamente iniciado
sleep 2

# Verificar que tenemos GPU disponible
if command -v nvidia-smi &> /dev/null; then
    echo "GPU detectada:"
    nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv
else
    echo "ADVERTENCIA: No se detectó GPU NVIDIA"
fi

echo "Cargando modelo: $VLLM_MODEL"
echo "Puerto: $VLLM_PORT"
echo "Host: $VLLM_HOST"
echo "GPU Memory Utilization: $VLLM_GPU_MEMORY_UTILIZATION"

# Verificar que las variables de entorno estén configuradas
if [ -z "$VLLM_MODEL" ]; then
    echo "ERROR: VLLM_MODEL no está configurado"
    exit 1
fi

# Iniciar vLLM con mejor logging
echo "Iniciando vLLM con modelo $VLLM_MODEL..."
exec vllm serve "$VLLM_MODEL" \
    --host "$VLLM_HOST" \
    --port "$VLLM_PORT" \
    --gpu-memory-utilization "$VLLM_GPU_MEMORY_UTILIZATION" 